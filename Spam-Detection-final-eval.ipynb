{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092ca0af",
   "metadata": {},
   "source": [
    "<h1 align='center'><b><font color='indianred'></p>Spam Detection HW - File 2</b></h1>\n",
    "\n",
    "<font color = 'indianred' size = 4 > </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807de07c",
   "metadata": {},
   "source": [
    "### <font color = 'blue'>IMPLEMENTING FINAL MODEL TO LARGER DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdaa78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "# Import scikit-learn classes for building models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Import the scipy library for working with sparse matrices\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# for treating class imbalance:\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ecb6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    !pip install -U nltk -qq\n",
    "    !pip install -U spacy -qq\n",
    "    !python -m spacy download en_core_web_sm -qq\n",
    "\n",
    "    basepath = '/content/drive/MyDrive/data'\n",
    "    sys.path.append('/content/drive/MyDrive/data/custom-functions')\n",
    "else:\n",
    "    basepath = '/Users/rechitasingh/Downloads/BUAN 6342 - NLP/0_Data'\n",
    "    sys.path.append(\n",
    "        '/Users/rechitasingh/Downloads/BUAN 6342 - NLP/0_Python_Scripts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing custom functions (Available from class notes)\n",
    "import custom_preprocessor_mod as cp\n",
    "from plot_learning_curve import plot_learning_curve\n",
    "from featurizer import ManualFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e15e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting base folder path; keeping all the files in same folder\n",
    "base_folder = Path(basepath)\n",
    "data_folder = base_folder\n",
    "model_folder = base_folder\n",
    "custom_functions = base_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04336b2b",
   "metadata": {},
   "source": [
    "## <font color='blue'>Loading saved Data & Model from Previous Workbook (File 1)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3ed819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting exact path for all files to be loaded\n",
    "# NOTE: Train test split is 70%-30% \n",
    "\n",
    "path_X_train_org_cleaned = model_folder / \\\n",
    "    'x_train_org_cleaned_sparse_embed.pkl'\n",
    "path_X_test_org_cleaned = model_folder / \\\n",
    "    'x_test_org_cleaned_sparse_embed.pkl'\n",
    "\n",
    "file_y_train_org = model_folder / \\\n",
    "    'y_train_org.pkl'\n",
    "file_y_test_org = model_folder / \\\n",
    "    'y_test_org.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1080ade4",
   "metadata": {},
   "source": [
    "**Imported the final train and test split from File 1**\n",
    "\n",
    "   **Note**: X_train_org and X_test_org are preprocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78d28416",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org_cleaned = joblib.load(path_X_train_org_cleaned)\n",
    "X_test_org_cleaned = joblib.load(path_X_test_org_cleaned)\n",
    "\n",
    "y_train_org = joblib.load(file_y_train_org)\n",
    "y_test_org =  joblib.load(file_y_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afc2cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "file_best_estimator_pipeline3 = model_folder / 'pipeline3_best_estimator.pkl'\n",
    "loaded_model = joblib.load(file_best_estimator_pipeline3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a96c6d",
   "metadata": {},
   "source": [
    "**Using custom featurizer for FeatureEngineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21b4d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rechitasingh/Downloads/BUAN 6342 - NLP/0_Python_Scripts/custom_preprocessor_mod.py:90: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "# Using custom featurizer mod\n",
    "featurizer = ManualFeatures(spacy_model='en_core_web_sm')\n",
    "\n",
    "X_train_features, feature_names = featurizer.fit_transform(X_train_org_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd31719",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>Pipeline 3 - Sparse Embeddings (TF-IDF) + Feature Engineering (6 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bba03f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining text and non text data from Part1 and PArt2\n",
    "\n",
    "X_train_final = pd.concat((pd.DataFrame(X_train_org_cleaned, columns=['cleaned_text']),\n",
    "                           pd.DataFrame(X_train_features, columns=feature_names)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd9126c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_characters</th>\n",
       "      <th>count_characters_no_space</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>count_digits</th>\n",
       "      <th>count_numbers</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>aux_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>goal arsenal 4 henry 7 v liverpool 2 henry sco...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>4.823529</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not send plus mode</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aah bless arm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oh k. come tomorrow</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yup ok</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  count_words  \\\n",
       "0  goal arsenal 4 henry 7 v liverpool 2 henry sco...         16.0   \n",
       "1                                 not send plus mode          4.0   \n",
       "2                                      aah bless arm          3.0   \n",
       "3                                oh k. come tomorrow          4.0   \n",
       "4                                             yup ok          2.0   \n",
       "\n",
       "   count_characters  count_characters_no_space  avg_word_length  count_digits  \\\n",
       "0              97.0                       82.0         4.823529           7.0   \n",
       "1              18.0                       15.0         3.000000           0.0   \n",
       "2              13.0                       11.0         2.750000           0.0   \n",
       "3              19.0                       16.0         3.200000           0.0   \n",
       "4               6.0                        5.0         1.666667           0.0   \n",
       "\n",
       "   count_numbers  noun_count  aux_count  verb_count  adj_count  ner  \n",
       "0            6.0         6.0       15.0         0.0        0.0  1.0  \n",
       "1            0.0         0.0        1.0         0.0        1.0  0.0  \n",
       "2            0.0         1.0        3.0         0.0        0.0  0.0  \n",
       "3            0.0         0.0        2.0         0.0        1.0  0.0  \n",
       "4            0.0         0.0        0.0         0.0        0.0  0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9afe8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return csr_matrix(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d3d3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline for sparse features and vectorizer\n",
    "\n",
    "sparse_features = Pipeline([('sparse', SparseTransformer()), ])\n",
    "vectorizer = Pipeline([('tfidf', TfidfVectorizer(max_features=5)), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54924e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3900x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 27774 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sparse_features.fit_transform(X_train_final.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79109bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3900x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1041 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit_transform(X_train_final.iloc[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e080d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', vectorizer, 'cleaned_text'),\n",
    "    ], remainder=sparse_features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2929eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.dtype:  float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 3.],\n",
       "       [0., 1., 0., ..., 0., 4., 2.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = combined_features.fit_transform(X_train_final)\n",
    "print('test.dtype: ', test.dtype)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f32d3d",
   "metadata": {},
   "source": [
    "## <font color ='blue'>**Training larger data on best model**</font>\n",
    "\n",
    "This pipeline will include the pipelines build before for vectorizer and sparcefeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18a6ec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;combined_features&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;sparse&#x27;,\n",
       "                                                              SparseTransformer())]),\n",
       "                                   transformers=[(&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfVectorizer(max_features=1000))]),\n",
       "                                                  &#x27;cleaned_text&#x27;)])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(C=10,\n",
       "                                    class_weight={&#x27;ham&#x27;: 1,\n",
       "                                                  &#x27;spam&#x27;: 3.5454545454545454},\n",
       "                                    max_iter=10000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;combined_features&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;sparse&#x27;,\n",
       "                                                              SparseTransformer())]),\n",
       "                                   transformers=[(&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfVectorizer(max_features=1000))]),\n",
       "                                                  &#x27;cleaned_text&#x27;)])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(C=10,\n",
       "                                    class_weight={&#x27;ham&#x27;: 1,\n",
       "                                                  &#x27;spam&#x27;: 3.5454545454545454},\n",
       "                                    max_iter=10000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">combined_features: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=Pipeline(steps=[(&#x27;sparse&#x27;, SparseTransformer())]),\n",
       "                  transformers=[(&#x27;tfidf&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                                  TfidfVectorizer(max_features=1000))]),\n",
       "                                 &#x27;cleaned_text&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">tfidf</label><div class=\"sk-toggleable__content\"><pre>cleaned_text</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;count_words&#x27;, &#x27;count_characters&#x27;, &#x27;count_characters_no_space&#x27;, &#x27;avg_word_length&#x27;, &#x27;count_digits&#x27;, &#x27;count_numbers&#x27;, &#x27;noun_count&#x27;, &#x27;aux_count&#x27;, &#x27;verb_count&#x27;, &#x27;adj_count&#x27;, &#x27;ner&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SparseTransformer</label><div class=\"sk-toggleable__content\"><pre>SparseTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, class_weight={&#x27;ham&#x27;: 1, &#x27;spam&#x27;: 3.5454545454545454},\n",
       "                   max_iter=10000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('combined_features',\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[('sparse',\n",
       "                                                              SparseTransformer())]),\n",
       "                                   transformers=[('tfidf',\n",
       "                                                  Pipeline(steps=[('tfidf',\n",
       "                                                                   TfidfVectorizer(max_features=1000))]),\n",
       "                                                  'cleaned_text')])),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=10,\n",
       "                                    class_weight={'ham': 1,\n",
       "                                                  'spam': 3.5454545454545454},\n",
       "                                    max_iter=10000))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the original training data\n",
    "loaded_model.fit(X_train_final, y_train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "094ab71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the 'loaded_model' contains the trained model with the best parameters\n",
    "# Using it to make predictions on new data\n",
    "# Final Pipeline\n",
    "def final_pipeline(text, classifier=None):\n",
    "    cleaned_text = text\n",
    "    X_features, feature_names = featurizer.fit_transform(text)\n",
    "    X_final = pd.concat((pd.DataFrame(cleaned_text, columns=['cleaned_text']),\n",
    "                         pd.DataFrame(X_features, columns=feature_names)), axis=1)\n",
    "    best_estimator_pipeline3 = classifier\n",
    "    predictions = best_estimator_pipeline3.predict(X_final)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed6eabba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rechitasingh/Downloads/BUAN 6342 - NLP/0_Python_Scripts/custom_preprocessor_mod.py:90: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "# predicted values for Test data set\n",
    "y_test_pred3 = final_pipeline(X_test_org_cleaned, loaded_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567f4e65",
   "metadata": {},
   "source": [
    "### <font color ='blue'>**Classification report for test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71ddcc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99      1448\n",
      "        spam       0.96      0.94      0.95       224\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.98      0.97      0.97      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest set classification report:\\n\\n',\n",
    "      classification_report(y_test_org, y_test_pred3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc1203",
   "metadata": {},
   "source": [
    "#### <font color ='blue'> Classification report inference </font>\n",
    "\n",
    "**Precision:**\n",
    "\n",
    "1. For the 'ham' class, the precision is 0.99, indicating that 99% of the instances predicted as 'ham' were correctly classified as 'ham.'\n",
    "2. For the 'spam' class, the precision is 0.96, meaning that 96% of the instances predicted as 'spam' were correctly classified as 'spam.'\n",
    "\n",
    "**Recall:**\n",
    "\n",
    "1. For the 'ham' class, the recall is 0.99, indicating that 99% of the actual 'ham' instances were correctly predicted as 'ham.'\n",
    "2. For the 'spam' class, the recall is 0.94, meaning that 94% of the actual 'spam' instances were correctly predicted as 'spam.'\n",
    "\n",
    "\n",
    "**F1-Score:**\n",
    "\n",
    "1. For the 'ham' class, the F1-score is 0.99, which is a very high value, indicating excellent performance in terms of precision and recall.\n",
    "2. For the 'spam' class, the F1-score is 0.95, which is also a relatively high score but slightly lower than for the 'ham' class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3efddcc",
   "metadata": {},
   "source": [
    "### <font color ='blue'> Final Inference </font>\n",
    "\n",
    "The model seem to perform well in the test data. \n",
    "\n",
    "**Final model is based out of Pipeline3 - Sparse Embeddings (TF-IDF) + Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395f852",
   "metadata": {},
   "source": [
    "## <font color='blue'> ******************************** THE END- FILE 2 ********************************</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
